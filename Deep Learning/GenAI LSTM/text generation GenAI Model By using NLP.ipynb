{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc95f48",
   "metadata": {},
   "source": [
    "# Simple GenAI Model using NLP (Step by Step)\n",
    "# 1. Problem Statement\n",
    "\n",
    "Objective:\n",
    "Build a Generative AI model that learns language patterns from a text dataset using NLP techniques and generates new text similar to the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c357f52c",
   "metadata": {},
   "source": [
    "# 2. Dataset\n",
    "\n",
    "A simple text file: data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db54f9d",
   "metadata": {},
   "source": [
    "# 3. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0fe342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9cc8e5",
   "metadata": {},
   "source": [
    "# 4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4ff020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"data.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc952f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "438bd695",
   "metadata": {},
   "source": [
    "# 5. NLP Preprocessing\n",
    "Steps:\n",
    "\n",
    "Lowercasing (already done)\n",
    "\n",
    "Remove punctuation\n",
    "\n",
    "Normalize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe00de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "# is pure NLP preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e303dcaf",
   "metadata": {},
   "source": [
    "# 6. Tokenization (NLP Step)\n",
    "Convert words into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dbed9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "total_words = len(word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a087eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bfd820d",
   "metadata": {},
   "source": [
    "# 7. Create Training Sequences (Language Modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1416da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_sequences = []\n",
    "\n",
    "for line in text.split(\"\\n\"):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        input_sequences.append(token_list[:i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7f3996",
   "metadata": {},
   "source": [
    "# 8. Padding Sequences\n",
    "\n",
    "Make all sequences the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d02b7b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_len = max(len(seq) for seq in input_sequences)\n",
    "\n",
    "input_sequences = pad_sequences(\n",
    "    input_sequences,\n",
    "    maxlen=max_len,\n",
    "    padding=\"pre\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0846429",
   "metadata": {},
   "source": [
    "# 9. Split Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a0577e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]\n",
    "\n",
    "y = np.eye(total_words)[y]   # One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e946c",
   "metadata": {},
   "source": [
    "# 10. Build GenAI Model (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "079986d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 50, input_length=max_len-1))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words, activation=\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93df2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e14d690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149d375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5b7d989",
   "metadata": {},
   "source": [
    "This is where NLP + GenAI meet:\n",
    "\n",
    "NLP gives structured text input\n",
    "\n",
    "LSTM learns sequence patterns\n",
    "\n",
    "Model predicts next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4735b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2514eab9",
   "metadata": {},
   "source": [
    "# 11. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87c0a714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.5689 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.5624 - accuracy: 0.0909\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.5560 - accuracy: 0.1818\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.5494 - accuracy: 0.1818\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.5428 - accuracy: 0.1818\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.5359 - accuracy: 0.1818\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.5287 - accuracy: 0.1818\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.5212 - accuracy: 0.1818\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.5132 - accuracy: 0.1818\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.5048 - accuracy: 0.1818\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.4957 - accuracy: 0.1818\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4859 - accuracy: 0.1818\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.4753 - accuracy: 0.1818\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.4638 - accuracy: 0.1818\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.4512 - accuracy: 0.1818\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.4375 - accuracy: 0.1818\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4226 - accuracy: 0.1818\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.4062 - accuracy: 0.1818\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3883 - accuracy: 0.1818\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3686 - accuracy: 0.1818\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3472 - accuracy: 0.1818\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3238 - accuracy: 0.1818\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2984 - accuracy: 0.1818\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2710 - accuracy: 0.1818\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2417 - accuracy: 0.1818\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2108 - accuracy: 0.1818\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.1788 - accuracy: 0.1818\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.1464 - accuracy: 0.1818\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.1147 - accuracy: 0.1818\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.0850 - accuracy: 0.1818\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0585 - accuracy: 0.1818\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.0353 - accuracy: 0.1818\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0146 - accuracy: 0.1818\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9941 - accuracy: 0.1818\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.9718 - accuracy: 0.1818\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9467 - accuracy: 0.1818\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9190 - accuracy: 0.1818\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8899 - accuracy: 0.1818\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.8609 - accuracy: 0.2727\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.8327 - accuracy: 0.2727\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8058 - accuracy: 0.4545\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7799 - accuracy: 0.5455\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7542 - accuracy: 0.5455\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7280 - accuracy: 0.5455\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7008 - accuracy: 0.5455\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.6721 - accuracy: 0.5455\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.6419 - accuracy: 0.5455\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6105 - accuracy: 0.5455\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5785 - accuracy: 0.4545\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5466 - accuracy: 0.5455\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5153 - accuracy: 0.5455\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4842 - accuracy: 0.5455\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4526 - accuracy: 0.5455\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4190 - accuracy: 0.5455\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3829 - accuracy: 0.6364\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3448 - accuracy: 0.6364\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3057 - accuracy: 0.6364\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2670 - accuracy: 0.6364\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2290 - accuracy: 0.7273\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1909 - accuracy: 0.8182\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1513 - accuracy: 0.8182\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1099 - accuracy: 0.8182\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0673 - accuracy: 0.8182\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0250 - accuracy: 0.8182\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9836 - accuracy: 0.8182\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9427 - accuracy: 0.8182\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9015 - accuracy: 0.8182\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8602 - accuracy: 0.8182\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8196 - accuracy: 0.9091\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7803 - accuracy: 0.9091\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7421 - accuracy: 0.9091\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7045 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6678 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6325 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5989 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5666 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5357 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5064 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4786 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4521 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4270 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4035 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3815 - accuracy: 1.0000\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3609 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3416 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3236 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3066 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2903 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2745 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2593 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2448 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2306 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2171 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2043 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1922 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1807 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1699 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1598 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1504 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1417 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2087ee63850>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X, y, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907ec471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e38aff29",
   "metadata": {},
   "source": [
    "# 12. Text Generation Function (GenAI Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a63f4e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_text(seed_text, next_words):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences(\n",
    "            [token_list], maxlen=max_len-1, padding=\"pre\"\n",
    "        )\n",
    "        predicted = model.predict(token_list, verbose=0)\n",
    "        predicted_word = tokenizer.index_word[np.argmax(predicted)]\n",
    "        seed_text += \" \" + predicted_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc877da7",
   "metadata": {},
   "source": [
    "# 13. Generate New Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c11785d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natural language learning learning is networks networks\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(generate_text(\"natural language\", 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47162e23",
   "metadata": {},
   "source": [
    "# Why?\n",
    "\n",
    ".pickle / .pkl → for scikit-learn models\n",
    "\n",
    "Deep learning models (LSTM, GRU) → saved as .h5 or .keras\n",
    "\n",
    "So for your GenAI + NLP LSTM model:\n",
    "\n",
    "Model → .h5 / .keras\n",
    "\n",
    "Tokenizer → .pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15772e0b",
   "metadata": {},
   "source": [
    "# 2. Save GenAI Model\n",
    "Save trained LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f7eca8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"text_gen_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0691bb",
   "metadata": {},
   "source": [
    "# Save Tokenizer (Important NLP part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "462c1d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c3a21d",
   "metadata": {},
   "source": [
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a77a0",
   "metadata": {},
   "source": [
    "# 3. Loading Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97384f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "model = load_model(\"text_gen_model.h5\")\n",
    "\n",
    "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1432e953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x20803b91330>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddba91ca",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147c23f3",
   "metadata": {},
   "source": [
    "# 4. Simple Deployment Logic (Function Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f47156e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_text(seed_text, next_words=5):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences(\n",
    "            [token_list], maxlen=max_len-1, padding=\"pre\"\n",
    "        )\n",
    "        predicted = model.predict(token_list, verbose=0)\n",
    "        seed_text += \" \" + tokenizer.index_word[np.argmax(predicted)]\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d986856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b33af70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "455fbcfa",
   "metadata": {},
   "source": [
    "# 6. Example: Streamlit Deployment (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b86338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import streamlit as st\n",
    "\n",
    "st.title(\"Simple GenAI Text Generator\")\n",
    "\n",
    "input_text = st.text_input(\"Enter seed text\")\n",
    "\n",
    "if st.button(\"Generate\"):\n",
    "    output = generate_text(input_text, 10)\n",
    "    st.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6bdf0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da57147c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a5b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5bbdd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
